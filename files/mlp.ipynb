{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "mlp_multi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIlITxeEXYHK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from model.deeplatent import *\n",
        "from model.networks import *\n",
        "from utils.utils import *\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
        "\n",
        "def modelnet_split(X,y):\n",
        "    return X[:12137,:],X[12137:,:],y[:12137],y[12137:]\n",
        "\n",
        "def smote(X,y):\n",
        "    #------------SMOTE----------------\n",
        "    #synthesize new data for those scarse categs\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    smt = SMOTE(random_state=42)\n",
        "    X, y = smt.fit_resample(X, y)\n",
        "    return X,y\n",
        "    #-------------END-----------------\n",
        "    \n",
        "def filter_cate(X,y,topk = 7):\n",
        "    cate_dict = {}\n",
        "    for i in y:\n",
        "        if i in cate_dict:\n",
        "            cate_dict[i] += 1\n",
        "        else:\n",
        "            cate_dict[i] = 1\n",
        "    cate_rank = sorted(cate_dict.items(),key=lambda x:x[1])[::-1][:topk]\n",
        "    cate_allow_lst = [i[0] for i in cate_rank]\n",
        "    \n",
        "    print(cate_rank)\n",
        "    print(cate_allow_lst)\n",
        "\n",
        "    filtered_X = []\n",
        "    filtered_y = []\n",
        "    for i in range(X.shape[0]):\n",
        "        if y[i] in cate_allow_lst:\n",
        "            filtered_X.append(X[i,:])\n",
        "            filtered_y.append(y[i])\n",
        "    print(len(filtered_X))\n",
        "    return np.array(filtered_X),filtered_y\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes = range(40),\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VNDpnbHXYHO"
      },
      "source": [
        "\n",
        "def randomForrest(X_train,X_test,y_train,y_test):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
        "                             random_state=42)\n",
        "    clf.fit(X_train, y_train) \n",
        "    y_pred =clf.predict(X_test)\n",
        "    accuracy_score(y_test, y_pred)\n",
        "    print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
        "    print(\"Test set score: %f\" % clf.score(X_test, y_test))\n",
        "    return y_pred\n",
        "        \n",
        "def mlp(X_train,X_test,y_train,y_test,iteration=3000):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    clf = MLPClassifier(max_iter=iteration, alpha=0.00007, hidden_layer_sizes = 1000,\n",
        "                    solver='sgd', verbose=10,  random_state=42,tol=0.000000001)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred =clf.predict(X_test)\n",
        "    accuracy_score(y_test, y_pred)\n",
        "    print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
        "    print(\"Test set score: %f\" % clf.score(X_test, y_test))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    return y_pred\n",
        "\n",
        "def svm_linear(X_train,X_test,y_train,y_test,C=0.01):\n",
        "    from sklearn.svm import LinearSVC\n",
        "    clf = LinearSVC(random_state=0, tol=1e-5,C=C)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred =clf.predict(X_test)\n",
        "    accuracy_score(y_test, y_pred)\n",
        "    print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
        "    print(\"Test set score: %f\" % clf.score(X_test, y_test))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BLJitrYtXYHY"
      },
      "source": [
        "####### test on modelnet sigma008 #######\n",
        "from data.dataloader import ModelNet40_aligned\n",
        "import glob\n",
        "import os\n",
        "import torch\n",
        "root='/home/mmvc/mmvc-ny-nas/Yi_Shi/data/modelnets/ModelNet40_poisson'\n",
        "\n",
        "ds = ModelNet40_aligned(root, None, mode='both')\n",
        "y = ds.label.ravel()\n",
        "\n",
        "latents = []\n",
        "subset_dirs = ['results/md40_aligned_full/md40_subset%d'%i for i in range(13)]\n",
        "\n",
        "for parent_dir in subset_dirs:\n",
        "    save_name_test = os.path.join(parent_dir,'model_best_test_latents.pt')\n",
        "    z_np = torch.load(save_name_test,map_location='cpu').detach().numpy()\n",
        "    latents.append(z_np)\n",
        "    print(z_np.shape)\n",
        "\n",
        "X = np.concatenate(latents,axis=0)\n",
        "train_num = ds.train_num\n",
        "print(X.shape,y.shape,train_num)\n",
        "\n",
        "X_train = X[:train_num,:]\n",
        "X_test  = X[train_num:,:]\n",
        "y_train = y[:train_num]\n",
        "y_test  = y[train_num:]\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "#y_pred = svm_linear(X_train, X_test, y_train, y_test, C=0.01)\n",
        "y_pred = mlp(X_train, X_test, y_train, y_test, iteration = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}